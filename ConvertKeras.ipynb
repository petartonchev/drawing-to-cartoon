{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvertKeras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "vJjGKVBna_mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "0749259d-f8ed-4900-ecf1-8f57c9b0fd84"
      },
      "cell_type": "code",
      "source": [
        "#@markdown This cell is to mount your Google Drive in Colaboratory. Run it and follow the instruction.\n",
        "\n",
        "mount_point = '/content/drive' #@param {type:'string'}\n",
        "\n",
        "import os\n",
        "if os.path.isdir(mount_point):\n",
        "  print(mount_point + ' has been already mounted.')\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount(mount_point)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OcpQLqTSbTZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "9ed7ef10-b2cd-4ba1-a0c5-83be7dcc14f2"
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ti3EqU2anOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "9fc572b2-ffdc-409f-cd17-943d0748dc87"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, BatchNormalization, Conv2DTranspose\n",
        "from keras.layers import  Dropout, Concatenate, Activation, Input\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import argparse\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "\n",
        "#create temp directory \n",
        "dirpath = 'tmp'\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Convert to keras')\n",
        "parser.add_argument('--dir', dest = \"dir\", default=\"output\",\n",
        "                   help='foulder that contains the checkpoints')\n",
        "parser.add_argument('--out', default='kerasmodel',\n",
        "                   help='output directory of the keras model')                      \n",
        "\n",
        "args = parser.parse_args('')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "do tuka\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "U10ww2ofjIeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "8ae6d50a-0a2d-48b3-e7b0-e672a3e9baa7"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with tf.Session() as sess:\n",
        "    saver= tf.train.import_meta_graph(args.dir+'/export.meta')\n",
        "    saver.restore(sess, args.dir+'/export')\n",
        "    idx = 0\n",
        "    variables = [v for v in tf.all_variables()]\n",
        "    idx = 0\n",
        "    for v in variables:\n",
        "        out = sess.run(v)\n",
        "        np.save(dirpath+'/'+str(idx)+'.npy', out)\n",
        "        idx += 1\n",
        "\n",
        "print('save weight files')\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "def gen_conv(x, out_channels):\n",
        "    y= Conv2D(filters = out_channels, kernel_size = 4, \n",
        "                                   strides = (2,2), padding = 'same', \n",
        "                                   kernel_initializer= 'zeros', input_shape = [256, 256, 3])(x)\n",
        "    return y\n",
        "def batchnorm(x):\n",
        "    return  BatchNormalization(axis=3)(x, training = 1)\n",
        "\n",
        "def lrelu(x, a):\n",
        "    return LeakyReLU(alpha=a)(x)\n",
        "\n",
        "def gen_deconv(x, out_channels):\n",
        "    y = Conv2DTranspose(out_channels, kernel_size=4, strides=(2, 2), padding=\"same\")(x)\n",
        "    return y\n",
        "\n",
        "\n",
        "def generator():\n",
        "    ngf = 64\n",
        "\n",
        "    input = Input(shape = [256, 256, 3])\n",
        "    layers = []\n",
        "    # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
        "    x = gen_conv(input, ngf)\n",
        "    layers.append(x)\n",
        "    \n",
        "    layer_specs = [\n",
        "        ngf * 2, # encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]\n",
        "        ngf * 4, # encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]\n",
        "        ngf * 8, # encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]\n",
        "        ngf * 8, # encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]\n",
        "        ngf * 8, # encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]\n",
        "        ngf * 8, # encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]\n",
        "        ngf * 8, # encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]\n",
        "    ]\n",
        "    \n",
        "    for out_channels in layer_specs:\n",
        "        x = lrelu(layers[-1], 0.2)\n",
        "        # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
        "        x = gen_conv(x, out_channels)\n",
        "        x = batchnorm(x)\n",
        "        layers.append(x)\n",
        "        \n",
        "    layer_specs = [\n",
        "        (ngf * 8, 0.5),   # decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]\n",
        "        (ngf * 8, 0.5),   # decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]\n",
        "        (ngf * 8, 0.5),   # decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]\n",
        "        (ngf * 8, 0.0),   # decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]\n",
        "        (ngf * 4, 0.0),   # decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]\n",
        "        (ngf * 2, 0.0),   # decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]\n",
        "        (ngf, 0.0),       # decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]\n",
        "    ]\n",
        "\n",
        "    num_encoder_layers = len(layers)\n",
        "    for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
        "        skip_layer = num_encoder_layers - decoder_layer - 1\n",
        "\n",
        "        if decoder_layer == 0:\n",
        "            in_data = layers[-1]\n",
        "        else:\n",
        "            in_data = Concatenate(axis=3)([layers[-1], layers[skip_layer]])\n",
        "        x = Activation('relu')(in_data)\n",
        "        # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
        "        x = gen_deconv(x, out_channels)\n",
        "        x = batchnorm(x)\n",
        "\n",
        "        if dropout > 0.0:\n",
        "            x = Dropout(dropout)(x)\n",
        "        layers.append(x)\n",
        "            \n",
        "    x = Concatenate(axis=3)([layers[-1], layers[0]])\n",
        "    x = Activation('relu')(x)\n",
        "    x = gen_deconv(x, 3)\n",
        "    output = Activation('tanh')(x)\n",
        "    layers.append(output)\n",
        "    \n",
        "    return Model(inputs = input, outputs = output)\n",
        "\n",
        "model = generator()\n",
        "print('model generated')\n",
        "\n",
        "weights = [] \n",
        "for i in range(0, 88):\n",
        "    name = dirpath+'/'+str(i)+'.npy'\n",
        "    weights.append(np.load(name))\n",
        "\n",
        "idx = 0 \n",
        "for layer in model.layers[1:]:\n",
        "    if 'conv2d' in layer.name:\n",
        "        W = weights[idx]\n",
        "        b = weights[idx+1]\n",
        "        layer.set_weights([W, b])\n",
        "        idx += 2\n",
        "    elif 'batch' in layer.name:\n",
        "        g = weights[idx]\n",
        "        b = weights[idx+1]\n",
        "        m = weights[idx+2]\n",
        "        v = weights[idx+3]\n",
        "        layer.set_weights([g, b, m, v])\n",
        "        idx += 4 \n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print('weights loaded')\n",
        "\n",
        "model.save(args.out+'/keras.h5')\n",
        "print('model saved to',  args.out)\n",
        "\n",
        "shutil.rmtree(dirpath)\n",
        "print('temp files removed')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from output/export\n",
            "WARNING:tensorflow:From <ipython-input-3-101bcfde2335>:6: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "save weight files\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "model generated\n",
            "weights loaded\n",
            "model saved to kerasmodel\n",
            "temp files removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kDcqgO1Ri3Hb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "64aebbd0-9b74-4b06-97bc-b3d088ccb8ae"
      },
      "cell_type": "code",
      "source": [
        "print('model saved to',  args.out)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model saved to kerasmodel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yDzN1Vb0nNH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "e294d904-9b66-49a9-e82e-8ce50cb6ce2e"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-6M8Oz73nO6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "bd1f6d7f-6d7c-4c2d-a67c-582280b7769d"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/79/29/35e1aa467436ff46b98df65a08c49faaedb3429e1c512d1d90fe308040a0/tensorflowjs-1.0.1-py3-none-any.whl\n",
            "Collecting tf-nightly-2.0-preview>=2.0.0.dev20190304 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/62/fcdfa11366542b978d76dde89a4870d5a23ef0211d0003fd001f0fb1cf3b/tf_nightly_2.0_preview-2.0.0.dev20190330-cp36-cp36m-manylinux1_x86_64.whl (84.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 84.7MB 334kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Requirement already satisfied: tensorflow-hub==0.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.3.0)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/17/a3d05a0664c11703259aa79d2b58b871b3bb1fff24153f75db04540489db/tb_nightly-1.14.0a20190319-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.33.1)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/31/88dd7539266d2debdf0eabd47ef4456d9f1685ce7339b8dd8b7029f7c41e/tensorflow_estimator_2.0_preview-1.14.0.dev2019033000-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K    100% |████████████████████████████████| 358kB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (40.8.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tb-nightly, google-pasta, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed google-pasta-0.1.4 numpy-1.15.1 tb-nightly-1.14.0a20190319 tensorflow-estimator-2.0-preview-1.14.0.dev2019033000 tensorflowjs-1.0.1 tf-nightly-2.0-preview-2.0.0.dev20190330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b2qCs2NDnZLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format keras kerasmodel/keras.h5 tensorflowjs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZiOXutcpnw8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls kerasmodel/tensorflowjs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Os2ZAp7Xn33s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}